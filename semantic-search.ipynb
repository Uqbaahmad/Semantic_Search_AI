{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\uqba2\\miniconda3\\envs\\ml\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "import numpy as np\n",
    "# from tqdm.autonotebook import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from haystack.document_stores import PineconeDocumentStore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define the name of your index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'semantic-search-ai'\n",
    "document_store = pinecone.init(\n",
    "    api_key=\"a88f41cf-3264-48d8-8a04-953f06214d55\",\n",
    "    environment = \"us-central1-gcp\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(index_name, dimension=len(embeds[0]))\n",
    "# connect to index\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `vblagoje/wikipedia_snippets_streamed` is a public dataset available on the Hugging Face Datasets platform. It contains a large collection of Wikipedia snippets, which are short summaries of Wikipedia articles, extracted from a dump of the English Wikipedia. The dataset includes over 5 million snippets, covering a wide range of topics and domains.\n",
    "\n",
    "###### You can access the dataset on the Hugging Face Datasets website at [https://huggingface.co/datasets/vblagoje/wikipedia_snippets_streamed](https://huggingface.co/datasets/vblagoje/wikipedia_snippets_streamed). The website provides detailed information about the dataset, including the format, size, and license.\n",
    "\n",
    "###### To use the dataset in Python, you can install the `datasets` library from Hugging Face and load the dataset using its name:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datasets.iterable_dataset.IterableDataset at 0x1b4c6761160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset('vblagoje/wikipedia_snippets_streamed',\n",
    "                    split='train',\n",
    "                    streaming=True)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The dataset is streamed, which means that the examples are not loaded into memory all at once. Instead, they are provided one by one as you iterate over the dataset. This makes it memory-efficient and suitable for large-scale natural language processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset = data.filter(lambda d:d['section_title'].startswith('History'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import EmbeddingRetriever\n",
    "from haystack.nodes import DensePassageRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\uqba2\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "retriever = DensePassageRetriever(document_store=document_store,\n",
    "                                 query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "                                 passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "                                 use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = EmbeddingRetriever(\n",
    "    document_store= document_store,\n",
    "    embedding_model=\"flax-sentence-embeddings/all_datasets_v3_mpnet-base\",\n",
    "    model_format='sentence_transformers',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Document\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91783931f15f42f69f98c8a676de62dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178f8469d22f4df695527ca0f0db2da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/256 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'write_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\uqba2\\OneDrive\\Documents\\Semantic_Search_AI\\semantic-search.ipynb Cell 17\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uqba2/OneDrive/Documents/Semantic_Search_AI/semantic-search.ipynb#X22sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i , doc \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(docs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uqba2/OneDrive/Documents/Semantic_Search_AI/semantic-search.ipynb#X22sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         doc\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m embeds[i]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/uqba2/OneDrive/Documents/Semantic_Search_AI/semantic-search.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     document_store\u001b[39m.\u001b[39;49mwrite_documents(docs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uqba2/OneDrive/Documents/Semantic_Search_AI/semantic-search.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     docs\u001b[39m.\u001b[39mclear()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uqba2/OneDrive/Documents/Semantic_Search_AI/semantic-search.ipynb#X22sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mif\u001b[39;00m counter \u001b[39m==\u001b[39m total_doc_count:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'write_documents'"
     ]
    }
   ],
   "source": [
    "# total_doc_count = 50000\n",
    "# batch_size = 256\n",
    "\n",
    "# counter = 0\n",
    "# docs=[]\n",
    "# for d in tqdm(df, total=total_doc_count):\n",
    "#     doc= Document(\n",
    "#         content=d['passage_text'],\n",
    "#         meta={\n",
    "#             'article_title':d['article_title'],\n",
    "#             'section_title':d['section_title'],\n",
    "#         }\n",
    "#     )\n",
    "#     docs.append(doc)\n",
    "#     counter += 1\n",
    "#     if counter % batch_size==0:\n",
    "#         embeds = retriever.embed_documents(docs)\n",
    "#         for i , doc in enumerate(docs):\n",
    "#             doc.embedding = embeds[i]\n",
    "#         document_store.write_documents(docs)\n",
    "#         docs.clear()\n",
    "#     if counter == total_doc_count:\n",
    "#         break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f743cc967148d2997674f7b3129685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DensePassageRetriever' object has no attribute 'embed_passages'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\uqba2\\OneDrive\\Documents\\Semantic_Search_AI\\semantic-search.ipynb Cell 18\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/uqba2/OneDrive/Documents/Semantic_Search_AI/semantic-search.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     doc \u001b[39m=\u001b[39m Document(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/uqba2/OneDrive/Documents/Semantic_Search_AI/semantic-search.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         content\u001b[39m=\u001b[39md[\u001b[39m'\u001b[39m\u001b[39mpassage_text\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/uqba2/OneDrive/Documents/Semantic_Search_AI/semantic-search.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         meta\u001b[39m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uqba2/OneDrive/Documents/Semantic_Search_AI/semantic-search.ipynb#X55sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uqba2/OneDrive/Documents/Semantic_Search_AI/semantic-search.ipynb#X55sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uqba2/OneDrive/Documents/Semantic_Search_AI/semantic-search.ipynb#X55sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     docs\u001b[39m.\u001b[39mappend(doc)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/uqba2/OneDrive/Documents/Semantic_Search_AI/semantic-search.ipynb#X55sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     embeddings\u001b[39m.\u001b[39mappend(retriever\u001b[39m.\u001b[39;49membed_passages([d[\u001b[39m'\u001b[39m\u001b[39mpassage_text\u001b[39m\u001b[39m'\u001b[39m]])[\u001b[39m0\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uqba2/OneDrive/Documents/Semantic_Search_AI/semantic-search.ipynb#X55sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Add documents and embeddings to the document store\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uqba2/OneDrive/Documents/Semantic_Search_AI/semantic-search.ipynb#X55sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m document_store\u001b[39m.\u001b[39mwrite_documents(docs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DensePassageRetriever' object has no attribute 'embed_passages'"
     ]
    }
   ],
   "source": [
    "# Create haystack document objects and embeddings\n",
    "docs = []\n",
    "embeddings = []\n",
    "for d in tqdm(filtered_dataset):\n",
    "    doc = Document(\n",
    "        content=d['passage_text'],\n",
    "        meta={\n",
    "            'article_title': d['article_title'],\n",
    "            'section_title': d['section_title'],\n",
    "        }\n",
    "    )\n",
    "    docs.append(doc)\n",
    "    embeddings.append(retriever.embed_passages([d['passage_text']])[0])\n",
    "\n",
    "# Add documents and embeddings to the document store\n",
    "document_store.write_documents(docs)\n",
    "document_store.update_embeddings(embeddings, ids=list(range(len(docs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_doc_count = 50000\n",
    "# batch_size = 256\n",
    "\n",
    "# docs = []\n",
    "# for i, d in enumerate(tqdm(df, total=total_doc_count)):\n",
    "#     doc = Document(\n",
    "#         content=d['passage_text'],\n",
    "#         meta={\n",
    "#             'article_title': d['article_title'],\n",
    "#             'section_title': d['section_title'],\n",
    "#         }\n",
    "#     )\n",
    "#     docs.append(doc)\n",
    "#     if (i + 1) % batch_size == 0 or (i + 1) == total_doc_count:\n",
    "#         embeds = retriever.embed_documents(docs)\n",
    "#         for j, doc in enumerate(docs):\n",
    "#             doc.embedding = embeds[j]\n",
    "#         document_store.write_documents(docs)\n",
    "#         docs.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from haystack.pipelines import DocumentSearchPipeline\n",
    "from haystack.utils import print_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "search_pipeline = DocumentSearchPipeline(retriever)\n",
    "result = search_pipeline.run(\n",
    "    query = \"When was the first electric power system built?\",\n",
    "    params={'retriever':{'top_k':2}}\n",
    ")\n",
    "print_documents(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initializing the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from haystack.nodes import Seq2SeqGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "generator = Seq2SeqGenerator(model_name_or_path='vblagoje/bart_lfqa')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initializing a Generative QA Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from haystack.pipelines import GenerativeQAPipeline\n",
    "pipe = GenerativeQAPipeline(generator, ret)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Asking Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "result = pipe.run(\n",
    "    query=\"what was the war of currents?\",\n",
    "    params={\n",
    "        'Retriever':{'top_k':3},\n",
    "        'Generator':{'top_k':1},\n",
    "    }\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "result = pipe.run(\n",
    "    query=\"what was the war of currents?\",\n",
    "    params={\n",
    "        'Retriever':{'top_k':3},\n",
    "        'Generator':{'top_k':1},\n",
    "    }\n",
    ")\n",
    "print_documents(result, details='minimum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "result = pipe.run(\n",
    "    query=\"what was the war of currents?\",\n",
    "    params={\n",
    "        'Ret':{'top_k':10},\n",
    "        'generator':{'top_k':1},\n",
    "    }\n",
    ")\n",
    "print_documents(result, details='minimum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "result = pipe.run(\n",
    "    query=\"What is the capital of France?\",\n",
    "    params={\n",
    "        'Ret':{'top_k':3},\n",
    "        'generator':{'top_k':1},\n",
    "    }\n",
    ")\n",
    "print_documents(result, details='minimum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define a function to generate embeddings for a list of documents\n",
    "def generate_embeddings(documents):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "    model = AutoModel.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "\n",
    "    embeddings = []\n",
    "    for doc in documents:\n",
    "        inputs = tokenizer(doc, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "        embedding = np.array(outputs[1].detach().numpy()[0])\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define a function to generate an embedding for a user query\n",
    "def generate_query_embedding(query):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "    model = AutoModel.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "\n",
    "    inputs = tokenizer(query, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    embedding = np.array(outputs[1].detach().numpy()[0])\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define a function to search for similar documents\n",
    "def search_similar_documents(query_embedding, top_k=10):\n",
    "    result = index.query(queries=[query_embedding], top_k=top_k)\n",
    "    return result.ids[0], result.scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Generate embeddings for your documents\n",
    "documents = data['text']\n",
    "document_embeddings = generate_embeddings(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Upload embeddings to the index\n",
    "index.upsert(ids=data['id'], embeddings=document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'ml (Python 3.9.13)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"search query\"\n",
    "query_embedding = generate_query_embedding(query)\n",
    "similar_docs_ids, similar_docs_scores = search_similar_documents(query_embedding)\n",
    "print(similar_docs_ids)\n",
    "print(similar_docs_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
